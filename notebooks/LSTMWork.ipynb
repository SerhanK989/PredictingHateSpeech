{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn import feature_extraction, linear_model, model_selection, metrics\n",
    "from sklearn import ensemble\n",
    "from scipy import sparse\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.make_model_lstm import hate_speech_model\n",
    "from src.lstm_cleaner import lstm_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#watch overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/labeled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df['tweet'].apply(lambda x: x.lstrip('!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.argmax(df[['hate_speech', 'offensive_language', 'neither']].values, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = nltk.tokenize.casual.TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = []\n",
    "wordDict = {}\n",
    "i = 1\n",
    "for tweet in tweets:\n",
    "    tokenized = token.tokenize(tweet)\n",
    "    newSent = []\n",
    "    for word in tokenized:\n",
    "        if word not in stop_words:\n",
    "            newWord = lemmatizer.lemmatize(word)\n",
    "            if newWord not in wordDict:\n",
    "                wordDict[newWord] = i\n",
    "                i += 1\n",
    "            newSent.append(newWord)\n",
    "            \n",
    "    cleaned.append(newSent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', '@mayasolovely', ':', 'As', 'woman', 'complain', 'cleaning', 'house', '.', '&', 'man', 'always', 'take', 'trash', '...']\n",
      "24783\n"
     ]
    }
   ],
   "source": [
    "print(cleaned[0])\n",
    "print(len(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxWords = max(map(len, cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq(sent, vocab, maxWords):\n",
    "    n = len(sent)\n",
    "    numZeros = maxWords - n\n",
    "    result = [0]*numZeros\n",
    "    \n",
    "    for word in sent:\n",
    "        if word in vocab:\n",
    "            result.append(vocab[word] + 2)\n",
    "        else:\n",
    "            result.append(1)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(list(map(lambda x: create_seq(x, wordDict, maxWords), cleaned)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = lstm_cleaner()\n",
    "sequences = c.clean_data(df['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = np.zeros((len(y), 3))\n",
    "for i, l in enumerate(y):\n",
    "    y_cat[i, l] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(sequences, y_cat, test_size = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41243\n"
     ]
    }
   ],
   "source": [
    "print(max(wordDict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Compiled...\n",
      "Train on 21188 samples, validate on 1116 samples\n",
      "Epoch 1/100\n",
      "21188/21188 [==============================] - 64s 3ms/sample - loss: 0.1324 - val_loss: 0.1424\n",
      "Epoch 2/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1311 - val_loss: 0.1407\n",
      "Epoch 3/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1293 - val_loss: 0.1382\n",
      "Epoch 4/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1268 - val_loss: 0.1355\n",
      "Epoch 5/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1253 - val_loss: 0.1346\n",
      "Epoch 6/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1249 - val_loss: 0.1344\n",
      "Epoch 7/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1245 - val_loss: 0.1341\n",
      "Epoch 8/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1242 - val_loss: 0.1338\n",
      "Epoch 9/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1238 - val_loss: 0.1334\n",
      "Epoch 10/100\n",
      "21188/21188 [==============================] - 58s 3ms/sample - loss: 0.1232 - val_loss: 0.1330\n",
      "Epoch 11/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1226 - val_loss: 0.1324\n",
      "Epoch 12/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1220 - val_loss: 0.1318\n",
      "Epoch 13/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1211 - val_loss: 0.1310\n",
      "Epoch 14/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1201 - val_loss: 0.1299\n",
      "Epoch 15/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1188 - val_loss: 0.1286\n",
      "Epoch 16/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1169 - val_loss: 0.1269\n",
      "Epoch 17/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1146 - val_loss: 0.1248\n",
      "Epoch 18/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1120 - val_loss: 0.1223\n",
      "Epoch 19/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1083 - val_loss: 0.1188\n",
      "Epoch 20/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1043 - val_loss: 0.1161\n",
      "Epoch 21/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.1003 - val_loss: 0.1139\n",
      "Epoch 22/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0965 - val_loss: 0.1107\n",
      "Epoch 23/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0926 - val_loss: 0.1084\n",
      "Epoch 24/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0889 - val_loss: 0.1092\n",
      "Epoch 25/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0857 - val_loss: 0.1047\n",
      "Epoch 26/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0820 - val_loss: 0.1067\n",
      "Epoch 27/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0788 - val_loss: 0.1014\n",
      "Epoch 28/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0752 - val_loss: 0.0998\n",
      "Epoch 29/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0719 - val_loss: 0.0978\n",
      "Epoch 30/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0682 - val_loss: 0.0988\n",
      "Epoch 31/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0655 - val_loss: 0.0957\n",
      "Epoch 32/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0622 - val_loss: 0.0948\n",
      "Epoch 33/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0598 - val_loss: 0.0930\n",
      "Epoch 34/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0567 - val_loss: 0.0933\n",
      "Epoch 35/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0547 - val_loss: 0.0926\n",
      "Epoch 36/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0534 - val_loss: 0.0915\n",
      "Epoch 37/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0504 - val_loss: 0.0941\n",
      "Epoch 38/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0484 - val_loss: 0.0952\n",
      "Epoch 39/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0471 - val_loss: 0.0937\n",
      "Epoch 40/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0454 - val_loss: 0.0939\n",
      "Epoch 41/100\n",
      "21188/21188 [==============================] - 57s 3ms/sample - loss: 0.0443 - val_loss: 0.0929\n"
     ]
    }
   ],
   "source": [
    "model = hate_speech_model()\n",
    "model.build_model()\n",
    "model.fit(X_train, y_train, epochs = 100, class_weight = {0: 1, 1: .05, 2: .15})\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8773220223226691\n"
     ]
    }
   ],
   "source": [
    "print(metrics.roc_auc_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis = 1)\n",
    "y_pred = np.argmax(preds, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.68      0.31       154\n",
      "           1       0.94      0.82      0.87      1921\n",
      "           2       0.84      0.61      0.71       404\n",
      "\n",
      "    accuracy                           0.77      2479\n",
      "   macro avg       0.66      0.70      0.63      2479\n",
      "weighted avg       0.88      0.77      0.81      2479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 105   44    5]\n",
      " [ 313 1567   41]\n",
      " [ 102   57  245]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "from tensorflow.keras.backend import set_session\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "config_proto = tf.ConfigProto()\n",
    "off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "session = tf.Session(config=config_proto)\n",
    "set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
